# === ğŸ“¦ imports ===

# æ¨™æº–åº«
import json
import re
import random

# Django
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt

# DRF
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework.permissions import AllowAny
from rest_framework import status
from rest_framework.test import APIRequestFactory
from rest_framework.request import Request
from rest_framework.parsers import JSONParser

# ğŸ”§ å…±ç”¨å·¥å…·
from .utils_common import normalize_text  # âœ… çµ±ä¸€æ”¹å¾é€™è£¡åŒ¯å…¥

# ğŸ§© åŠŸèƒ½ä¸€ï¼šæ¢ä»¶åˆ†æ
from .utils_semantic import extract_negative_phrases, split_conditions

# ğŸ§  åŠŸèƒ½å››ï¼šæ¬„ä½è£œå¼·
from .utils_card_enhancer import enrich_restaurant_info

# ğŸ“Š åŠŸèƒ½ä¸‰-1ï¼šèªæ„åˆ†ç´š
from .utils_prompt import analyze_prompt_level

# ğŸ§° åŠŸèƒ½äºŒ & å…±ç”¨
from .utils_card import (
    generate_map_url, format_open_status, generate_price_description,
    extract_district, expand_exclusions, collect_blob,
    deduplicate_semantic, uniq_keep_order, sort_reasons,
    FEATURE_REASON_MAP, STYLE_REASON_MAP, USER_INPUT_RULES
)



# åŠŸèƒ½ 1ï¼šåå‘æ¨è–¦æ¢ä»¶æ“·å–ï¼ˆå¼·åŒ–ç‰ˆ v6 - èªæ„è£œå¼·å®Œå…¨å‘½ä¸­ï¼‰

class ExtractNegativeConditionsView(APIView):
    permission_classes = [AllowAny]

    def post(self, request):
        req_type = request.data.get('type')
        user_input = request.data.get('text', '').strip()

        if req_type != 'text' or not user_input:
            return Response({
                "status": "error",
                "data": None,
                "message": "è«‹æä¾› type='text' ä¸”åŒ…å« text æ¬„ä½"
            }, status=status.HTTP_400_BAD_REQUEST)

        # âœ… ä¿ç•™ä½ åŸæœ¬çš„å¸¸æ•¸è¨­è¨ˆ
        FUNCTION_PREFIXES = ['æ¨è–¦', 'é¤å»³', 'åœ°æ–¹', 'é‚£å®¶', 'é€™å®¶', 'åº—å®¶', 'åƒ', 'æƒ³åƒ', 'æä¾›']
        TAIL_PARTICLES = r'[çš„äº†å‘¢å•¦å•Šå˜›å”·å–”å“¦è€¶å‘€å›‰å§]*$'
        PRESERVE_TERMS = ['åƒåˆ°é£½', 'æ—©åˆé¤', 'å®µå¤œ', 'å¥—é¤', 'å…§ç”¨', 'å¤–å¸¶']
        CLEAN_SUFFIXES = ['çš„æ–™ç†', 'æ–™ç†', 'åº—å®¶', 'é¤å»³', 'é¡å‹', 'é¡', 'é‚£å®¶', 'é€™å®¶', 'åº—']
        EXCLUSION_WHITELIST = ['è¾£å¦¹', 'è¾£å€‹', 'è¾£å€‹å¥³ç”Ÿ', 'ç«è¾£çš„éŸ³æ¨‚']
        BLACKLIST_SUFFIX = ['é‚£ç¨®', 'é€™ç¨®']

        # âœ… èªæ„æ˜ å°„è¡¨ï¼ˆå®Œå…¨ä¿ç•™ï¼‰
        SEMANTIC_NEGATIVE_MAP = {
            "å¤ªæ²¹": "æ²¹è†©", "å¾ˆæ²¹": "æ²¹è†©", "æ²¹è†©": "æ²¹è†©", "å¤ªè†©": "æ²¹è†©", "åƒå®Œæœƒè†©": "æ²¹è†©",
            "ç”œåˆ°è†©": "ç”œè†©", "å¤ªè²´": "é«˜åƒ¹", "åƒ¹æ ¼å¤ªé«˜": "é«˜åƒ¹", "CP å€¼å¤ªä½": "é«˜åƒ¹",
            "ä»½é‡å°‘åˆè²´": "é«˜åƒ¹", "ä¸å¤ é£½": "ä»½é‡å°‘", "å¤ªåµ": "åµé›œ", "å¾ˆåµ": "åµé›œ",
            "å¤ªæ“ ": "æ“æ“ ", "ä¸å¤ªä¹¾æ·¨": "ä¸ä¹¾æ·¨", "è¡›ç”Ÿä¸å¥½": "ä¸ä¹¾æ·¨", "ä¸ä¹¾æ·¨": "ä¸ä¹¾æ·¨",
            "å¤ªé¹¹": "é‡å£å‘³", "å¤ªè¾£": "é‡å£å‘³", "å¤ªé¹¹å¤ªè¾£": "é‡å£å‘³",
            "å¤ªå¤šé†¬": "é†¬å¤š", "å¤ªå¤šé†¬çš„": "é†¬å¤š", "é›·": "é›·åº—", "æœ‰é»é›·": "é›·åº—",
            "é›·åº—": "é›·åº—", "å¤ªæ–‡é’": "æ–‡é’é¢¨æ ¼", "é€™ç¨®å¤ªæ–‡é’çš„": "æ–‡é’é¢¨æ ¼",
            "ç¶²ç¾åº—": "ç¶²ç¾åº—", "æ‰“å¡åº—": "ç¶²ç¾åº—", "Instagram æ‰“å¡": "ç¶²ç¾åº—"
        }

        excluded_items = []

        # âœ… 1. å¥å­åŒ¹é…
        matches = extract_negative_phrases(user_input)

        # âœ… 2. æŠ½è©èˆ‡æ¸…æ´—
        for phrase in matches:
            if isinstance(phrase, tuple):
                phrase = phrase[1] if len(phrase) > 1 else phrase[0]
            words = split_conditions(phrase)

            for word in words:
                if not word or word in EXCLUSION_WHITELIST or word in BLACKLIST_SUFFIX:
                    continue

                if word in PRESERVE_TERMS:
                    cleaned = word
                elif word.endswith("çš„") and word[:-1] in PRESERVE_TERMS:
                    cleaned = word[:-1]
                else:
                    for prefix_word in FUNCTION_PREFIXES:
                        if word.startswith(prefix_word):
                            word = word[len(prefix_word):]
                            break
                    word = re.sub(TAIL_PARTICLES, '', word)
                    for suffix in CLEAN_SUFFIXES:
                        if word.endswith(suffix) and len(word) > len(suffix):
                            word = word[:-len(suffix)]
                            break
                    cleaned = word

                if cleaned and len(cleaned) <= 6 and re.match(r'^[\u4e00-\u9fffA-Za-z0-9]+$', cleaned):
                    excluded_items.append(cleaned)

        # âœ… 3. é¡å¤–èªæ„è£œå¼·
        for phrase, keyword in SEMANTIC_NEGATIVE_MAP.items():
            if phrase in user_input and keyword not in excluded_items:
                excluded_items.append(keyword)

        # âœ… 4. æœ€çµ‚æ­£è¦åŒ–èˆ‡å»é‡
        final_excluded = []
        for kw in excluded_items:
            normalized = SEMANTIC_NEGATIVE_MAP.get(kw, kw)
            if normalized not in final_excluded:
                final_excluded.append(normalized)

        return Response({
            "status": "success",
            "data": {
                "excluded": final_excluded
            },
            "message": "å·²æ“·å–åå‘æ¨è–¦æ¢ä»¶"
        }, status=status.HTTP_200_OK)



# åŠŸèƒ½ 2ï¼šæ¨è–¦ç†ç”±è£œå¼· + çµæ§‹åŒ–è¼¸å‡ºï¼ˆå¼·åŒ–ç‰ˆï¼šå»é‡èˆ‡æ’åº + ä¿åº•æ’é™¤é–˜é–€ï¼‰
class GenerateRecommendReasonView(APIView):
    permission_classes = [AllowAny]

    def post(self, request):
        import json

        DEBUG = True

        user_input = (request.data.get("user_input", "") if hasattr(request, "data") else "").lower().strip()
        req_excluded_items = (request.data.get("excluded_items", []) if hasattr(request, "data") else []) or []

        if hasattr(request, 'data'):
            req_type = request.data.get('type')
            restaurants = request.data.get('restaurants', [])
        else:
            req_type = request.POST.get('type')
            try:
                restaurants = json.loads(request.body.decode()).get("restaurants", [])
            except Exception:
                restaurants = []

        if req_type != 'restaurant_list' or not isinstance(restaurants, list):
            return Response({
                "status": "error",
                "data": None,
                "message": "è«‹æä¾› type='restaurant_list' ä¸”åŒ…å« restaurants æ¸…å–®"
            }, status=status.HTTP_400_BAD_REQUEST)

        # ========== ä¿åº•æ’é™¤æ©Ÿåˆ¶ ==========
        def extract_negatives(text: str) -> list:
            import re
            if not text:
                return []
            pattern = re.compile(
                r"(?:ä¸æƒ³åƒ|ä¸æƒ³è¦|ä¸è¦|ä¸åƒ|åˆ¥æ¨è–¦|ä¸è¦æ¨è–¦)\s*"
                r"([^\nï¼Œ,ã€‚ï¼!ï¼Ÿ?\s]+(?:(?:[ã€,/å’Œèˆ‡åŠæˆ–]|æˆ–æ˜¯|[,ï¼Œ/ ])+[^\nï¼Œ,ã€‚ï¼!ï¼Ÿ?\s]+)*)"
            )
            m = pattern.search(text)
            if not m:
                return []
            seg = m.group(1)
            parts = re.split(r"(?:[ã€,/å’Œèˆ‡åŠæˆ–]|æˆ–æ˜¯|[,ï¼Œ\s])+", seg)
            return [p.strip() for p in parts if p.strip()]

        extracted_from_input = extract_negatives(user_input)
        raw_excluded = list({x for x in (req_excluded_items + extracted_from_input) if x})
        expanded_ex = set(expand_exclusions(raw_excluded))

        if DEBUG:
            print("ğŸ§© æ“´å……å¾Œæ’é™¤è©ï¼š", sorted(expanded_ex))

        filtered_restaurants = []
        debug_hits = []
        for r in restaurants:
            blob = collect_blob(r)
            hit = next((ex for ex in expanded_ex if ex in blob), None)
            if hit:
                debug_hits.append((r.get("name", ""), hit))
            else:
                filtered_restaurants.append(r)

        # fallbackï¼šè‹¥ä¸€é–“éƒ½æ²’å‰”é™¤ï¼Œå†æª¢æŸ¥ name
        if len(filtered_restaurants) == len(restaurants) and raw_excluded:
            tmp = []
            for r in filtered_restaurants:
                name = r.get("name", "")
                if any(x in name for x in raw_excluded):
                    debug_hits.append((name, f"fallback:{'/'.join(raw_excluded)}"))
                else:
                    tmp.append(r)
            filtered_restaurants = tmp

        if DEBUG:
            print("ğŸ” è¢«æ’é™¤æ¸…å–®/å‘½ä¸­è©ï¼š", debug_hits)

        restaurants = filtered_restaurants
        # ==================================

        results = []
        for r in restaurants:
            name = r.get('name', '')
            address = r.get('address', '')
            rating = r.get('rating', 0)
            is_open_raw = r.get('is_open')
            price_level = r.get('price_level', '')
            review_count = r.get('review_count')
            distance_m = r.get('distance_m')
            reason_score = r.get('reason_score', 0)

            map_url = generate_map_url(name)
            is_open = format_open_status(is_open_raw)
            price_desc = generate_price_description(price_level)
            district = extract_district(address)
            distance = f"{distance_m} å…¬å°º" if distance_m else "æœªçŸ¥"

            highlight = r.get('highlight', '')
            matched_tags = r.get('matched_tags', [])
            features = r.get('features', [])
            style = r.get('style', '')
            opening_hours = r.get('opening_hours', '')

            ai_reason = r.get('ai_reason', '')
            comment_summary = r.get('comment_summary', '')

            # æ ¸å¿ƒæ¨è–¦ç†ç”±
            reason_source = "inference"
            if ai_reason:
                core_reason = ai_reason
                reason_source = "ai"
            elif comment_summary:
                core_reason = comment_summary
                reason_source = "summary"
            else:
                core_reasons = []
                if rating >= 4.5:
                    core_reasons.append("è©•åƒ¹å¾ˆé«˜")
                if "å°åŒ—" in address or "æ–°åŒ—" in address:
                    core_reasons.append("åœ°é»æ–¹ä¾¿")
                if not core_reasons:
                    core_reasons.append("æ•´é«”è©•åƒ¹ä¸éŒ¯")
                core_reason = "ã€".join(core_reasons)

            # è£œå¼·æ¨è–¦é—œéµå­—
            extra_reasons = []
            if highlight:
                extra_reasons.append(highlight)
            if matched_tags:
                extra_reasons.extend(matched_tags)
            if price_desc:
                extra_reasons.append(price_desc)
            if district:
                extra_reasons.append(f"ä½æ–¼{district}")
            for f in features:
                if f in FEATURE_REASON_MAP:
                    extra_reasons.append(FEATURE_REASON_MAP[f])
            if style in STYLE_REASON_MAP:
                extra_reasons.append(STYLE_REASON_MAP[style])
            if opening_hours:
                if "00" in opening_hours or "02" in opening_hours:
                    extra_reasons.append("å¤œé–“ç‡Ÿæ¥­")
                if "23" in opening_hours or "22" in opening_hours:
                    extra_reasons.append("é©åˆå®µå¤œ")
                if "å…¨å¤©" in opening_hours:
                    extra_reasons.append("å…¨å¤©ç‡Ÿæ¥­")
            if user_input:
                for k, v in USER_INPUT_RULES.items():
                    if k in user_input:
                        extra_reasons.append(v)

            # âœ… èªæ„å»é‡ + æ’åº
            clean_reasons = deduplicate_semantic(extra_reasons)
            sorted_reasons = sort_reasons(clean_reasons)
            full_reason = "ã€".join([core_reason] + sorted_reasons)

            tags = uniq_keep_order(list(matched_tags) + list(sorted_reasons))

            results.append({
                "name": name,
                "address": address,
                "rating": rating,
                "price_level": price_level,
                "review_count": review_count,
                "highlight": highlight,
                "tags": tags,
                "matched_tags": matched_tags,
                "is_open": is_open,
                "distance": distance,
                "reason_score": reason_score,
                "map_url": map_url,
                "reason_summary": {
                    "source": reason_source,
                    "core": core_reason,
                    "extra": sorted_reasons
                },
                "recommend_reason": full_reason
            })

        sorted_results = sorted(results, key=lambda x: (
            x.get('reason_score') or 0,
            x.get('rating') or 0,
            x.get('review_count') or 0
        ), reverse=True)

        return Response({
            "status": "success",
            "data": {
                "results": sorted_results
            },
            "message": "æ¨è–¦ç†ç”±å·²ç”¢ç”Ÿ"
        }, status=status.HTTP_200_OK)


# åŠŸèƒ½ 3-1ï¼šæ¨¡ç³Šèªå¥æç¤ºï¼ˆæœ€çµ‚å„ªåŒ–ç‰ˆï¼‰
class GeneratePromptView(APIView):
    permission_classes = [AllowAny]

    def post(self, request):
        req_type = request.data.get("type")
        user_input = request.data.get("text", "").strip()

        if req_type != "text" or not user_input:
            return Response({
                "status": "error",
                "data": None,
                "message": "è«‹æä¾› type='text' ä¸”åŒ…å« text æ¬„ä½"
            }, status=status.HTTP_400_BAD_REQUEST)

        # âœ… å‘¼å« utils ä¸­çš„åˆ†æé‚è¼¯
        level, guidance = analyze_prompt_level(user_input)

        return Response({
            "status": "success",
            "data": {
                "level": level,
                "guidance": guidance
            },
            "message": "æ¨¡ç³Šèªå¥æç¤ºå·²ç”¢ç”Ÿ"
        }, status=status.HTTP_200_OK)

# åŠŸèƒ½ 3-2ï¼šäº’å‹•å¼èªå¥å¼•å°å»ºè­°ï¼ˆé‡æ§‹ç‰ˆï¼‰
class SuggestInputGuidanceView(APIView):
    permission_classes = [AllowAny]

    def post(self, request):
        req_type = request.data.get("type")
        user_input = request.data.get("text", "").lower().strip()

        if req_type != "text" or not user_input:
            return Response({
                "status": "error",
                "data": None,
                "message": "è«‹æä¾› type='text' ä¸”åŒ…å« text æ¬„ä½"
            }, status=status.HTTP_400_BAD_REQUEST)

        summary = []
        default_guidance = "æ‚¨å¯ä»¥è¼¸å…¥æƒ³åƒçš„é¡å‹ã€å ´åˆã€é ç®—ç­‰è³‡è¨Šï¼Œæˆ‘å€‘æœƒçµ¦æ‚¨æ›´å¥½çš„å»ºè­°ï¼"

        # ğŸ§  è¦å‰‡å®šç¾©ï¼ˆåˆ†é¡ã€é—œéµå­—ã€å›æ‡‰ï¼‰
        RULES = [
            ("é£²é£Ÿåå¥½", ['ä¸åƒè¾£', 'æ€•è¾£', 'æˆ‘ä¸åƒè¾£'], 'å·²æ’é™¤è¾£å‘³é¸é …ï¼Œæ¨è–¦æ¸…çˆ½ã€æ¹¯å“ç­‰æº«å’Œå£å‘³'),
            ("é£²é£Ÿåå¥½", ['ä¸åƒç‰›', 'æˆ‘ä¸åƒç‰›'], 'å·²æ’é™¤ç‰›è‚‰é¤é»ï¼Œå¯æ¨è–¦é›è‚‰ã€æµ·é®®æˆ–è”¬é£Ÿ'),
            ("é£²é£Ÿåå¥½", ['ä¸åƒæµ·é®®', 'æµ·é®®éæ•'], 'å·²æ’é™¤æµ·é®®é¤å»³ï¼Œæ¨è–¦å…¶ä»–é¡å‹'),
            ("é£²é£Ÿåå¥½", ['åƒç´ ', 'ç´ é£Ÿ', 'æˆ‘åƒç´ '], 'å·²è­˜åˆ¥ç‚ºç´ é£Ÿéœ€æ±‚ï¼Œå¯æ¨è–¦ç´ é£Ÿæˆ–è”¬é£Ÿå‹å–„é¤å»³'),

            ("ç”¨é¤å ´åˆ", ['æœ‹å‹èšé¤', 'åŒå­¸èšé¤', 'èšæœƒ'], 'é©åˆæœ‹å‹èšæœƒï¼Œå¯æ¨è–¦å¹³åƒ¹ç†±é¬§æˆ–å¤šäººå¥—é¤é¤å»³'),
            ("ç”¨é¤å ´åˆ", ['å®¶åº­èšé¤', 'å®¶äººåƒé£¯', 'å®¶æ—èšé¤', 'çˆ¸åª½'], 'é©åˆå®¶åº­ç”¨é¤ï¼Œå»ºè­°é¸æ“‡ç’°å¢ƒå®‰éœã€å¤šæ¨£èœè‰²çš„é¤å»³'),
            ("ç”¨é¤å ´åˆ", ['ç´„æœƒ'], 'æ°£æ°›ä½³çš„æ¨è–¦é©åˆç´„æœƒï¼Œå¯è€ƒæ…®å’–å•¡å»³æˆ–è£æ½¢æº«é¦¨çš„é¤å»³'),
            ("ç”¨é¤å ´åˆ", ['å•†å‹™', 'è«‹å®¢', 'æ­£å¼'], 'æ¨è–¦ç©©é‡æ°£æ°›èˆ‡é«˜è©•åƒ¹çš„é¤å»³ï¼Œé©åˆæ­£å¼æˆ–å•†å‹™ç”¨é€”'),
            ("ç”¨é¤å ´åˆ", ['æ…¶ç”Ÿ', 'ç”Ÿæ—¥', 'æ…¶ç¥'], 'æ¨è–¦æ°£æ°›ä½³ã€æœ‰è›‹ç³•æˆ–åŒ…å»‚çš„é¤å»³ï¼Œé©åˆæ…¶ç¥å ´åˆ'),
            ("ç”¨é¤å ´åˆ", ['å°å­©', 'å°æœ‹å‹', 'å¸¶å­©å­', 'å…’ç«¥'], 'é©åˆè¦ªå­ç”¨é¤ï¼Œå»ºè­°è€ƒæ…®æœ‰å…’ç«¥é¤æˆ–å¯¬æ•ç©ºé–“çš„åº—å®¶'),
            ("ç”¨é¤å ´åˆ", ['é•·è¼©', 'çˆ¶æ¯', 'å®¶äººä¸€èµ·åƒ'], 'å»ºè­°é¸æ“‡ç’°å¢ƒå®‰éœã€é¤é»æ¸…æ·¡çš„å®¶åº­å‹å–„é¤å»³'),

            ("é ç®—", ['ä¸è²´', 'ä¾¿å®œ', 'å¹³åƒ¹', 'åƒ¹æ ¼å¯¦æƒ '], 'åå¥½ä¸è²´çš„é¤å»³ï¼Œå¯ä»¥å„ªå…ˆæŸ¥çœ‹å¹³åƒ¹é«˜è©•åƒ¹é¸é …'),
            ("é ç®—", ['é«˜ç´š', 'é«˜åƒ¹', 'ç²¾è‡´', 'é«˜ç«¯'], 'åå¥½ç²¾ç·»é«”é©—ï¼Œå¯æ¨è–¦é«˜è©•åƒ¹æˆ–é«˜ç«¯é¤å»³'),

            ("æ™‚æ®µ", ['å®µå¤œ', 'æ·±å¤œ'], 'æ¨è–¦å®µå¤œæ™‚æ®µç‡Ÿæ¥­ä¸­çš„è¼•é£Ÿã€ç‚¸ç‰©æˆ–æ‹‰éºµç­‰åº—å®¶'),
            ("æ™‚æ®µ", ['æ—©åˆé¤'], 'å¯æ¨è–¦æ°£æ°›ä½³ã€è©•åƒ¹é«˜çš„æ—©åˆé¤åº—'),
            ("æ™‚æ®µ", ['æ—©é¤'], 'æ¨è–¦ç‡Ÿæ¥­ä¸­çš„ä¸­è¥¿å¼æ—©é¤é¸é …'),

            ("æ–™ç†é¡å‹", ['ç”œé»'], 'æ¨è–¦ç”œé»è©•åƒ¹é«˜çš„é¤å»³æˆ–å’–å•¡å»³'),
            ("æ–™ç†é¡å‹", ['æ‹‰éºµ', 'æ—¥å¼'], 'å¯æ¨è–¦é«˜åˆ†æ—¥å¼é¤å»³èˆ‡æ‹‰éºµååº—'),
            ("æ–™ç†é¡å‹", ['éŸ“å¼'], 'æ¨è–¦é«˜äººæ°£éŸ“å¼æ–™ç†'),
            ("æ–™ç†é¡å‹", ['ä¸­å¼'], 'ä¸­å¼é¤å»³é¸æ“‡è±å¯Œï¼Œæ¨è–¦åˆèœæˆ–ä¾¿ç•¶å‹åº—å®¶'),
            ("æ–™ç†é¡å‹", ['ç¾©å¼', 'ç¾©å¤§åˆ©éºµ'], 'å¯æ¨è–¦ç¾©å¼æ–™ç†èˆ‡ç¾©å¤§åˆ©éºµå°ˆé–€åº—'),
            ("æ–™ç†é¡å‹", ['ç¾å¼', 'æ¼¢å ¡'], 'æ¨è–¦é«˜è©•åƒ¹ç¾å¼æ¼¢å ¡æˆ–ç‚¸ç‰©é¤å»³'),

            ("é£²é£Ÿç‹€æ…‹", ['åƒä¸å¤š', 'åƒå°‘ä¸€é»', 'ç°¡å–®åƒ', 'è¼•é£Ÿ'], 'æ¨è–¦è¼•é£Ÿé¡å‹å¦‚ä¸‰æ˜æ²»ã€æ²™æ‹‰æˆ–æ—©åˆé¤'),
            ("é£²é£Ÿç‹€æ…‹", ['è¶•æ™‚é–“', 'å¿«é€Ÿåƒ', 'æ™‚é–“ä¸å¤š'], 'æ¨è–¦ä¾›é¤å¿«é€Ÿæˆ–å¤–å¸¶æ–¹ä¾¿çš„é¸é …'),
            ("é£²é£Ÿç‹€æ…‹", ['å¤©æ°£å†·', 'æƒ³åƒç†±çš„', 'æš–èƒƒ'], 'æ¨è–¦æ¹¯å“ã€ç«é‹æˆ–ç†±ç‚’ç­‰æº«æš–æ–™ç†'),
            ("é£²é£Ÿç‹€æ…‹", ['æƒ³åƒè¾£', 'é‡å£å‘³', 'è¾£çš„æ–™ç†', 'éº»è¾£', 'è¾£é‹'], 'é©åˆé‡å£å‘³æ„›å¥½è€…ï¼Œæ¨è–¦éº»è¾£ç«é‹ã€å·èœæˆ–éŸ“å¼è¾£ç‚’ç­‰é¤å»³'),
            ("é£²é£Ÿç‹€æ…‹", ['æ¸…æ·¡', 'ä¸æƒ³å¤ªæ²¹', 'åƒæ¸…çˆ½çš„'], 'æ¨è–¦æ¸…çˆ½æˆ–æ¹¯å“é¡å‹ï¼Œé©åˆå£å‘³è¼ƒæ·¡çš„éœ€æ±‚'),
        ]

        # âœ… å…±ç”¨åˆ¤æ–·å‡½å¼
        def match_any(keywords: list, text: str) -> bool:
            return any(k in text for k in keywords)

        # âœ… å…ˆæª¢æŸ¥æ’é™¤èªå¥ + ç‰¹å®šæ–™ç†é¡å‹
        if match_any(['ä¸æƒ³åƒ', 'ä¸åƒ', 'ä¸è¦'], user_input) and match_any(
            ['ç”œé»', 'æ‹‰éºµ', 'æ—¥å¼', 'éŸ“å¼', 'ä¸­å¼', 'ç¾©å¼', 'ç¾©å¤§åˆ©éºµ', 'ç¾å¼', 'æ¼¢å ¡', 'ç‡’çƒ¤', 'ç«é‹'], user_input):
            summary.append({"type": "æ’é™¤èªå¥", "message": "å·²æ’é™¤ç‰¹å®šæ–™ç†é¡å‹ï¼Œå¯æ¨è–¦å…¶ä»–é¸é …"})

        # âœ… è¦å‰‡æ¯”å°é‚è¼¯
        for category, keywords, message in RULES:
            if match_any(keywords, user_input):
                summary.append({"type": category, "message": message})

        if not summary:
            summary.append({"type": "å…¶ä»–", "message": default_guidance})

        guidance_combined = "ï¼›".join([item["message"] for item in summary])
        levels = list({item["type"] for item in summary})

        return Response({
            "status": "success",
            "data": {
                "summary": summary,
                "guidance": guidance_combined,
                "level": levels
            },
            "message": "å·²ç”¢ç”Ÿèªæ„å¼•å°å»ºè­°"
        }, status=status.HTTP_200_OK)


# åŠŸèƒ½ 4ï¼šæ¨è–¦å¡ç‰‡æ¬„ä½æ¨¡æ“¬è¼¸å‡ºï¼ˆé‡æ§‹ç‰ˆï¼‰

class GenerateCardDataView(APIView):
    permission_classes = [AllowAny]

    def post(self, request):
        # âœ… æ”¯æ´ JSON æ ¼å¼çš„å®‰å…¨è™•ç†
        if hasattr(request, 'data'):
            req_type = request.data.get('type')
            restaurants = request.data.get('restaurants', [])
        else:
            req_type = request.POST.get('type')
            try:
                restaurants = json.loads(request.body.decode()).get("restaurants", [])
            except Exception:
                restaurants = []

        if req_type != 'restaurant_list' or not isinstance(restaurants, list):
            return Response({
                "status": "error",
                "data": None,
                "message": "è«‹æä¾› type='restaurant_list' ä¸”åŒ…å« restaurants æ¸…å–®"
            }, status=status.HTTP_400_BAD_REQUEST)

        # âœ… å‘¼å«è£œå¼·é‚è¼¯
        results = [enrich_restaurant_info(r) for r in restaurants]

        return Response({
            "status": "success",
            "data": {
                "results": results
            },
            "message": "å¡ç‰‡æ¬„ä½è³‡æ–™å·²ç”¢ç”Ÿ"
        }, status=status.HTTP_200_OK)



# âœ… æ•´åˆæ¸¬è©¦ï¼šåŠŸèƒ½ä¸€ â†’ å›› â†’ äºŒï¼ˆæœ€çµ‚å¼·åŒ–ç‰ˆï¼Œä¸€æ¬¡åˆ°ä½ï¼‰
class IntegrationTestView(APIView):
    permission_classes = [AllowAny]
    parser_classes = [JSONParser]  # âœ… æ”¯æ´ application/json

    def post(self, request):
        from .sample_data import RESTAURANTS_SAMPLE
        from .views import ExtractNegativeConditionsView, GenerateCardDataView, GenerateRecommendReasonView

        factory = APIRequestFactory()

        input_text = request.data.get("text", "").strip()

        # âœ… å®‰å…¨å¸ƒæ—è§£æï¼šé¿å… "false" ä»è¢«ç•¶æˆ True
        raw_allow = request.data.get("allow_backfill", True)
        if isinstance(raw_allow, str):
            allow_backfill = raw_allow.strip().lower() in ("1", "true", "t", "yes", "y", "on")
        else:
            allow_backfill = bool(raw_allow)

        if not input_text:
            return Response({
                "status": "error",
                "data": None,
                "message": "è«‹æä¾› text æ¬„ä½"
            }, status=status.HTTP_400_BAD_REQUEST)

        print("\nğŸ¯ æ•´åˆæ¸¬è©¦é–‹å§‹ >>>")
        print(f"ğŸ“ ä½¿ç”¨è€…è¼¸å…¥ï¼š{input_text}")
        print(f"ğŸ§© allow_backfill = {allow_backfill}")

        # =========================
        # âœ… Step 1ï¼šåŠŸèƒ½ä¸€ï¼ˆæ’é™¤æ¢ä»¶æ“·å–ï¼‰
        request_exclusion = factory.post("/fake_path/", {"text": input_text}, format='json')
        wrapped_request = Request(request_exclusion, parsers=[JSONParser()])
        exclusion_response = ExtractNegativeConditionsView().post(wrapped_request)

        if hasattr(exclusion_response, "data") and isinstance(exclusion_response.data, dict):
            exclusion_data_raw = exclusion_response.data
        elif hasattr(exclusion_response, "_data") and isinstance(exclusion_response._data, dict):
            exclusion_data_raw = exclusion_response._data
        else:
            exclusion_data_raw = {}

        excluded_items = []
        if isinstance(exclusion_data_raw, dict):
            data_field = exclusion_data_raw.get("data", {})
            if isinstance(data_field, dict):
                excluded_items = data_field.get("excluded", [])
        print(f"ğŸš« ä¸Šæ¸¸æ’é™¤é …ç›®ï¼š{excluded_items}")

        # =========================
        # âœ… Step 2ï¼šé€²éšæ¯”å°æ’é™¤ï¼ˆæ¸…ç†æ¨™é»/å…¨å½¢ç©ºç™½ + åŒç¾©è© + åˆä½µæ¬„ä½å­—ä¸² + äºŒæ¬¡ä¿åº• + å¯æ§è£œä½ï¼‰
        import re

        def _normalize(s: str) -> str:
            if not isinstance(s, str):
                return ""
            s = s.strip().lower()
            # ç§»é™¤å¸¸è¦‹ä¸­è‹±æ¨™é»ã€å…¨å½¢ç©ºç™½èˆ‡ç¬¦è™Ÿ
            s = re.sub(r"[ï¼Œ,ã€‚.!ï¼Ÿ?ã€/\\|()\[\]ã€ã€‘{}\-ï¼¿_~^'\"`ï¼š:ï¼›;@#*$ï¼‹+ï¼=ï¼Â·ï½¥\s]+", "", s)
            return s

        def _expand_exclusions(items: list) -> list:
            mapping = {
                "ç”œé»": ["ç”œé»", "ç”œå“", "ç”œé£Ÿ", "è›‹ç³•", "çƒ˜ç„™", "ä¸‹åˆèŒ¶", "ç”œé»åº—", "ç”œé»å°ˆé–€", "ç”œé»è©•åƒ¹é«˜"],
                "æ‹‰éºµ": ["æ‹‰éºµ", "ramen"],
                "ç‡’çƒ¤": ["ç‡’çƒ¤", "çƒ¤è‚‰", "ç‚­ç«", "ç‡’è‚‰"],
                "æ¼¢å ¡": ["æ¼¢å ¡", "burger"],
                "ç¾å¼": ["ç¾å¼", "ç¾å¼é¤å»³", "ç¾å¼é¢¨æ ¼", "ç¾å¼æ¼¢å ¡"],
                "ç«é‹": ["ç«é‹", "é‹ç‰©", "æ¶®æ¶®é‹", "éº»è¾£é‹"],
            }
            expanded = set()
            for it in items or []:
                raw = (it or "").strip()
                norm = _normalize(raw)
                if not norm:
                    continue
                # åŸå­—èˆ‡æ­£è¦åŒ–å­—éƒ½æ‹¿å» mapping æ‰¾åŒç¾©è©
                candidates = set([raw, norm])
                for key, syns in mapping.items():
                    if key == raw or key == norm:
                        candidates |= set(syns)
                # æ‰€æœ‰å€™é¸è©æ­£è¦åŒ–å¾ŒåŠ å…¥
                for c in candidates:
                    expanded.add(_normalize(c))
            return list(expanded)

        def _collect_blob(r: dict) -> str:
            # æŠŠå¯èƒ½åŒ…å«å“é¡è¨Šæ¯çš„æ¬„ä½åˆä½µï¼Œæå‡å‘½ä¸­ç‡
            parts = []
            for k in ["name", "highlight", "ai_reason", "comment_summary", "style", "address"]:
                v = r.get(k, "")
                if v:
                    parts.append(str(v))
            for lk in ["matched_tags", "tags", "features"]:
                seq = r.get(lk) or []
                parts.extend([str(t) for t in seq])
            return _normalize("ï½œ".join(parts))

        expanded_ex = set(_expand_exclusions(excluded_items))
        print(f"ğŸ§© æ“´å……å¾Œæ’é™¤è©ï¼ˆnormï¼‰ï¼š{sorted(expanded_ex)}")

        # çµ±ä¸€å…ˆç”Ÿæˆæ¯é–“é¤å»³çš„ã€Œæ­£è¦åŒ–åˆä½µå­—ä¸²ã€
        normalized_blobs = [(_collect_blob(r), r) for r in RESTAURANTS_SAMPLE]

        filtered = []
        debug_hits = []
        for blob, r in normalized_blobs:
            hit = None
            for ex in expanded_ex:
                if ex and ex in blob:
                    hit = ex
                    break
            if hit:
                debug_hits.append((r.get("name", ""), hit))
            else:
                filtered.append(r)

        # ğŸ›¡ï¸ äºŒæ¬¡ä¿åº•ï¼šè‹¥å®Œå…¨æ²’å‰”é™¤ï¼Œç”¨ã€Œåç¨±åŒ…å«åŸå§‹æ’é™¤è©ã€å†éä¸€è¼ª
        if len(filtered) == len(RESTAURANTS_SAMPLE):
            _raw_ex = [(it or "").strip() for it in (excluded_items or []) if (it or "").strip()]
            if _raw_ex:
                tmp = []
                for r in filtered:
                    name = r.get("name", "")
                    if any(x in name for x in _raw_ex):
                        debug_hits.append((name, f"fallback:{'/'.join(_raw_ex)}"))
                    else:
                        tmp.append(r)
                filtered = tmp

        print(f"âœ… é€šéæ’é™¤ç¯©é¸çš„é¤å»³æ•¸ï¼š{len(filtered)}")
        print("ğŸ” è¢«æ’é™¤æ¸…å–®/å‘½ä¸­è©ï¼š", debug_hits)

        # â€”â€” è£œä½æ©Ÿåˆ¶ï¼ˆå¯æ§ï¼‰â€”â€”
        TARGET_N = 5
        before_fill = len(filtered)
        used_backfill_pool = False

        if allow_backfill and len(filtered) < TARGET_N:
            picked_names = set(r.get("name", "") for r in filtered)
            candidate_pool = []
            for r in RESTAURANTS_SAMPLE:
                nm = r.get("name", "")
                if nm in picked_names:
                    continue
                blob = _collect_blob(r)
                if any(ex in blob for ex in expanded_ex):
                    continue
                candidate_pool.append(r)

            # ç”¨ ratingã€review_count åšæ’åºè£œä½
            candidate_pool.sort(
                key=lambda x: (float(x.get("rating") or 0), int(x.get("review_count") or 0)),
                reverse=True
            )
            for r in candidate_pool:
                if len(filtered) >= TARGET_N:
                    break
                nm = r.get("name", "")
                if nm not in picked_names:
                    filtered.append(r)
                    picked_names.add(nm)

        # å¯é¸ï¼šå¾Œå‚™åå–®ï¼ˆè‹¥ä»ä¸è¶³ 5ï¼‰
        if allow_backfill and len(filtered) < TARGET_N:
            BACKFILL_POOL = [
                {
                    "name": "é’è”¬ä¾¿ç•¶èˆ–",
                    "address": "å°åŒ—å¸‚ä¸­æ­£å€",
                    "rating": 4.3, "review_count": 210,
                    "price_level": "$", "style": "å®¶å¸¸",
                    "features": ["åƒ¹æ ¼å¯¦æƒ ", "å¿«é€Ÿæ–¹ä¾¿"],
                    "matched_tags": ["ç´ é£Ÿéœ€æ±‚", "æ¸…çˆ½å£å‘³"],
                    "highlight": "å¹³åƒ¹æ¸…çˆ½",
                    "ai_reason": "å¹³åƒ¹æ¸…çˆ½ã€ä¾¿ç•¶é¸æ“‡å¤šï¼Œé©åˆå¿«é€Ÿç”¨é¤",
                },
                {
                    "name": "å°å··æ¸…ç²¥åº—",
                    "address": "å°åŒ—å¸‚å¤§åŒå€",
                    "rating": 4.2, "review_count": 180,
                    "price_level": "$", "style": "å‚³çµ±",
                    "features": ["æ¸…çˆ½å£å‘³", "è¦ªå­å‹å–„"],
                    "matched_tags": ["æ¸…çˆ½å£å‘³"],
                    "highlight": "æ¸…ç²¥å°èœ",
                    "ai_reason": "å£å‘³æ¸…çˆ½ã€é©åˆå¸¶é•·è¼©ï¼Œé¤é»é¸æ“‡å¤š",
                },
                {
                    "name": "å—æ´‹ç±³ç·šé¤¨",
                    "address": "å°åŒ—å¸‚è¬è¯å€",
                    "rating": 4.4, "review_count": 260,
                    "price_level": "$$", "style": "æ±å—äºé¢¨",
                    "features": ["åƒ¹æ ¼å¯¦æƒ ", "é«˜ CP å€¼"],
                    "matched_tags": ["æ±å—äºé¢¨æ ¼", "åƒ¹æ ¼å¯¦æƒ "],
                    "highlight": "ç•°åœ‹é¢¨å‘³",
                    "ai_reason": "æ±å—äºé¢¨å‘³ã€ä»½é‡å……è¶³ã€åƒ¹æ ¼å¯¦æƒ ",
                },
            ]
            picked_names = set(r.get("name", "") for r in filtered)
            safe_backfills = []
            for r in BACKFILL_POOL:
                if r["name"] in picked_names:
                    continue
                blob = _collect_blob(r)
                if any(ex in blob for ex in expanded_ex):
                    continue
                safe_backfills.append(r)

            safe_backfills.sort(
                key=lambda x: (float(x.get("rating") or 0), int(x.get("review_count") or 0)),
                reverse=True
            )
            for r in safe_backfills:
                if len(filtered) >= TARGET_N:
                    break
                filtered.append(r)
                picked_names.add(r.get("name", ""))
                used_backfill_pool = True

        if allow_backfill:
            print(
                f"ğŸ“Œ è£œä½å¾Œçš„é¤å»³æ•¸ï¼š{len(filtered)}ï¼ˆç›®æ¨™ {TARGET_N}ï¼‰ï¼›"
                f"ä¾†æºï¼š{'BACKFILL_POOL' if used_backfill_pool else ('RESTAURANTS_SAMPLE' if len(filtered) > before_fill else 'ç„¡')}"
            )

        # =========================
        # âœ… Step 3ï¼šåŠŸèƒ½å››ï¼ˆæ¬„ä½è£œå¼·ï¼‰
        request_card_data = factory.post("/fake_path/", {
            "type": "restaurant_list",
            "restaurants": filtered
        }, format='json')
        wrapped_card_request = Request(request_card_data, parsers=[JSONParser()])
        card_data_response = GenerateCardDataView().post(wrapped_card_request)

        if hasattr(card_data_response, "data") and isinstance(card_data_response.data, dict):
            card_data_raw = card_data_response.data
        elif hasattr(card_data_response, "_data") and isinstance(card_data_response._data, dict):
            card_data_raw = card_data_response._data
        else:
            card_data_raw = {}

        card_restaurants = card_data_raw.get("data", {}).get("results", [])
        print(f"ğŸ“¦ è£œå®Œæ¬„ä½çš„é¤å»³æ•¸ï¼š{len(card_restaurants)}")

        # =========================
        # âœ… Step 4ï¼šåŠŸèƒ½äºŒï¼ˆæ¨è–¦ç†ç”±è£œå¼· + ä¿åº•æ’é™¤ï¼‰
        request_reason = factory.post("/fake_path/", {
            "type": "restaurant_list",
            "restaurants": card_restaurants,
            "user_input": input_text,
            "excluded_items": excluded_items,   # â­ é—œéµï¼šæŠŠä¸Šæ¸¸æ’é™¤è©å‚³ä¸‹å»
        }, format='json')
        wrapped_reason_request = Request(request_reason, parsers=[JSONParser()])
        final_response = GenerateRecommendReasonView().post(wrapped_reason_request)

        if hasattr(final_response, "data") and isinstance(final_response.data, dict):
            final_data_raw = final_response.data
        elif hasattr(final_response, "_data") and isinstance(final_response._data, dict):
            final_data_raw = final_response._data
        else:
            final_data_raw = {}

        # æ­£ç¢ºè¨ˆç®—æœ€çµ‚ç­†æ•¸ï¼ˆresults æ˜¯ listï¼‰
        results_list = final_data_raw.get("data", {}).get("results", [])
        print(f"ğŸŒŸ æœ€çµ‚æ¨è–¦çµæœç­†æ•¸ï¼š{len(results_list) if isinstance(results_list, list) else 0}")

        # âœ… å›å‚³çµæ§‹ï¼šç¶­æŒä½ åŸæœ¬é¢¨æ ¼ï¼Œå¤–åŠ æŠŠ excluded_items ä¸€èµ·å›å‚³ï¼Œæ–¹ä¾¿æ¸¬è©¦å°å‡ºæˆ–é©—è­‰
        return Response({
            "status": "success",
            "data": final_data_raw.get("data", {}),
            "excluded_items": excluded_items,
            "message": "æ•´åˆæµç¨‹å·²åŸ·è¡Œå®Œæˆ"
        }, status=status.HTTP_200_OK)

