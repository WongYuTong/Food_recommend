import re
from tqdm import tqdm
import emoji
from .ml_models import ws_driver, pos_driver, zero_shot, sentiment, kw_model
from post.models import Post
from restaurants.models import RestaurantIndicatorDetail
from django.utils import timezone

def clean_text(text):
    # ç§»é™¤ emoji
    text = emoji.replace_emoji(text, replace='')
    # å¯åœ¨æ­¤åŠ å…¥æ›´å¤šé›œè¨Šæ¸…ç†è¦å‰‡ï¼ˆå¦‚å¤šé¤˜ç©ºç™½ã€ç‰¹æ®Šç¬¦è™Ÿç­‰ï¼‰
    text = re.sub(r'[\s]+', ' ', text)
    return text.strip()

def analyze_restaurant_indicators(post_id):
    try:
        post = Post.objects.get(id=post_id)
    except Post.DoesNotExist:
        print(f"æ‰¾ä¸åˆ°è²¼æ–‡ ID {post_id}")
        return

    content = post.content
    place_id = post.location_place_id
    if not place_id:
        print(f"è²¼æ–‡ ID {post_id} ç¼ºå°‘ place_idï¼Œç„¡æ³•åˆ†æ")
        return

    candidate_labels = ["é«”é©—", "é£Ÿç‰©", "æœå‹™", "åƒ¹æ ¼", "ç’°å¢ƒ", "å…¶ä»–"]
    sentiment_labels = ["æ­£é¢", "ä¸­ç«‹", "è² é¢"]
    overall_keywords = ["å†ä¾†", "æ¨è–¦", "ä¸æœƒå†ä¾†", "ä¸‹æ¬¡", "å¤§å®¶", "å€¼å¾—", "ä¸æ¨", "ä¸æ¨è–¦"]

    print(f"\n====== åˆ†æè²¼æ–‡ ID {post_id} ======")
    print("åŸæ–‡ï¼š", content)
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!ï¼Ÿï¼Œ,ï½~]+|\\s{2,}', content)
    sentences = [s for s in sentences if s.strip()]
    ws_list = ws_driver(sentences)
    pos_list = pos_driver(ws_list)
    stopwords = set(["çš„", "äº†", "å’Œ", "å¯ä»¥", "é‚„æœ‰", "å¾ˆå¤š", "è‡ªå·±", "åˆ°", "è·Ÿ", "æœ‰", "æ˜¯", "åœ¨", "è¦", "å¾ˆ", "ä¸", "å†", "æœƒ", "ä¾†", "åŠ ", "åš"])
    valid_pos = set(["Na", "Nb", "Nc", "A", "V"])
    last_keywords = None
    sentence_to_keywords = []
    keyword_to_category = {}
    keyword_to_sentences = {}
    for sent, ws, pos in zip(sentences, ws_list, pos_list):
        is_summary = any(kw in sent for kw in overall_keywords)
        # CKIP æ–·è©+è©æ€§éæ¿¾+å»é™¤åœç”¨è©+é•·åº¦>1
        ckip_words = [w for w, p in zip(ws, pos) if p in valid_pos and w not in stopwords and len(w) > 1]
        # KeyBERT é—œéµè©ï¼ˆé™åˆ¶é•·åº¦6ä»¥å…§ï¼‰
        keybert_keywords = [kw for kw, score in kw_model.extract_keywords(sent, top_n=2) if len(kw) <= 6]
        # åˆä½µä¸¦å»é‡ï¼ˆä¿ç•™æœ€çŸ­çš„é—œéµè©ï¼‰
        all_keywords = ckip_words + keybert_keywords
        keywords = []
        for k in all_keywords:
            if not any((k != other and k in other) for other in all_keywords):
                keywords.append(k)
        keywords = list(dict.fromkeys(keywords))  # å»é‡ä¸”ä¿ç•™é †åº
        print(f"å¥å­ï¼šã€Œ{sent}ã€â†’ é—œéµè©ï¼š{keywords}")
        if keywords:
            last_keywords = keywords
            for keyword in keywords:
                if keyword not in keyword_to_category:
                    # summary/overall é—œéµè©ç›´æ¥åˆ†é¡ç‚ºé«”é©—
                    if any(kw in keyword for kw in overall_keywords):
                        best_label = "é«”é©—"
                        score = 1.0
                    elif any(x in keyword for x in ["å¸Œæœ›", "å»ºè­°", "æœŸæœ›", "å¦‚æœèƒ½", "å¸Œæœ›èƒ½"]):
                        best_label = "å…¶ä»–"
                        score = 1.0
                    elif "åƒ¹æ ¼" in keyword or "è²´" in keyword or "ä¾¿å®œ" in keyword or "CP" in keyword:
                        best_label = "åƒ¹æ ¼"
                        score = 1.0
                    elif any(food in keyword for food in ["å°æ–™","æ¹¯é ­", "å£å‘³","é£²æ–™"]):
                        best_label = "é£Ÿç‰©"
                        score = 1.0
                    elif any(env in keyword for env in ["æ¨“ä¸Š", "é¢¨æ™¯", "è£æ½¢", "æ°£æ°›", "ç’°å¢ƒ", "åœ°é»", "ä½ç½®", "ç©ºé–“"]):
                        best_label = "ç’°å¢ƒ"
                        score = 1.0
                    elif any(srv in keyword for srv in ["ç´°ç¯€", "äººå“¡", "æ…‹åº¦"]):
                        best_label = "æœå‹™"
                        score = 1.0
                    else:
                        result = zero_shot(keyword, candidate_labels=candidate_labels)
                        best_label = result['labels'][0]
                        score = result['scores'][0]
                    if best_label == "å…¶ä»–":
                        sent_result = zero_shot(sent, candidate_labels=candidate_labels)
                        sent_label = sent_result['labels'][0]
                        sent_score = sent_result['scores'][0]
                        if sent_label != "å…¶ä»–" and sent_score > 0.5:
                            best_label = sent_label
                            score = sent_score
                    if best_label != "å…¶ä»–" and score <= 0.5:
                        continue
                    keyword_to_category[keyword] = best_label
                    keyword_to_sentences.setdefault(keyword, []).append(sent)
        else:
            if last_keywords:
                for keyword in last_keywords:
                    keyword_to_sentences.setdefault(keyword, []).append(sent)
        sentence_to_keywords.append(last_keywords)
    category_sentiments = {cat: [] for cat in candidate_labels}
    positive_emojis = ["ğŸ˜Š", "ğŸ‘", "XD", "ğŸ˜‚", "ğŸ˜", ":D", ":)", "^_^", "^O^", "ğŸ˜ƒ", "ğŸ˜„", "ğŸ˜†", "ğŸ˜", "ğŸ¥°", "ğŸ˜‹", "ğŸ˜"]
    negative_emojis = ["ğŸ˜¡", "ğŸ‘", "QQ", "å“­", ":(", ">:(", "T_T", "QAQ", "ğŸ˜¢", "ğŸ˜", "ğŸ˜ ", "ğŸ˜£", "ğŸ˜–", "ğŸ˜”"]
    positive_extreme_words = ["è¶…è®š", "è¶…æ£’", "è¶…å¥½åƒ", "è¶…æ»¿æ„", "è¶…æ¨è–¦", "è¶…å–œæ­¡", "è¶…å€¼"]
    negative_extreme_words = ["è¶…çˆ›", "è¶…é›£åƒ", "è¶…å¤±æœ›", "è¶…ç³Ÿç³•", "è¶…å·®", "è¶…è¨å­"]
    neutral_patterns = ["é»äº†"]
    sentiment_words = ["å¥½åƒ", "é›£åƒ", "æ¨è–¦", "å¤±æœ›", "æ»¿æ„", "è¨å­", "æ£’", "å–œæ­¡", "æ¨", "ä¸æ¨", "ä¸æ¨è–¦", "ä¸å€¼å¾—", "å€¼å¾—", "è®š"]
    summary_positive = ["ä¸‹æ¬¡é‚„è¦ä¾†åƒ", "ä¸‹æ¬¡é‚„æœƒå†ä¾†", "é‚„è¦ä¾†", "é‚„æœƒä¾†", "å€¼å¾—", "æ¨è–¦çµ¦å¤§å®¶"]
    weaken_words = ["æœ‰é»", "ç¨å¾®", "æœ‰äº›"]
    def has_sentiment_word(sent, sentiment_words):
        return any(w in sent for w in sentiment_words)
    for keyword, cat in keyword_to_category.items():
        if 'cat_sent_added' not in locals():
            cat_sent_added = {c: set() for c in candidate_labels}
        first_print = True
        for sent in keyword_to_sentences.get(keyword, []):
            if sent in cat_sent_added[cat]:
                continue
            if first_print:
                print(f"\n  é—œéµè©ï¼š{keyword}ï¼ˆåˆ†é¡ï¼š{cat}ï¼‰")
                first_print = False
            pos_bonus = 0.2 if (any(e in sent for e in positive_emojis) or any(w in sent for w in positive_extreme_words)) else 0.0
            neg_bonus = 0.2 if (any(e in sent for e in negative_emojis) or any(w in sent for w in negative_extreme_words)) else 0.0
            sent_for_model = clean_text(sent)
            if any(sp in sent_for_model for sp in summary_positive):
                sent_label = "æ­£é¢"
                sent_score = 0.5
            elif any(p in sent_for_model for p in neutral_patterns) and not has_sentiment_word(sent_for_model, sentiment_words):
                sent_label = "ä¸­ç«‹"
                sent_score = 0.0
            else:
                sent_result = sentiment(sent_for_model, candidate_labels=sentiment_labels)
                sent_label = sent_result['labels'][0]
                sent_score = sent_result['scores'][0]
            if sent_label == "æ­£é¢":
                score_val = sent_score + pos_bonus - neg_bonus
            elif sent_label == "è² é¢":
                score_val = -sent_score - neg_bonus + pos_bonus
            else:
                score_val = 0 + pos_bonus - neg_bonus
            if any(w in sent for w in weaken_words):
                if sent_label == "æ­£é¢":
                    score_val -= 0.35
                elif sent_label == "è² é¢":
                    score_val += 0.35
            score_val = max(min(score_val, 1.0), -1.0)
            if sent_label == "è² é¢":
                if score_val <= -0.5:
                    mapped_score = 1 + (score_val + 1) * (1/0.5)
                    mapped_score = min(max(mapped_score, 1), 2)
                else:
                    mapped_score = 2 + (score_val + 0.5) * (1/0.5)
                    mapped_score = min(max(mapped_score, 2), 3)
            elif sent_label == "ä¸­ç«‹":
                mapped_score = 3
            else:
                if score_val <= 0.5:
                    mapped_score = 3 + score_val * (1/0.5)
                    mapped_score = min(max(mapped_score, 3), 4)
                else:
                    mapped_score = 4 + (score_val - 0.5) * (1/0.5)
                    mapped_score = min(max(mapped_score, 4), 5)
            print(f"    å¥å­ï¼šã€Œ{sent}ã€â†’ æƒ…æ„Ÿï¼š{sent_label}ï¼ˆåŸåˆ†æ•¸ï¼š{score_val:.2f}ï¼Œäº”åˆ†åˆ¶ï¼š{mapped_score:.2f}ï¼‰")
            category_sentiments[cat].append(mapped_score)
            cat_sent_added[cat].add(sent)
    print("\nåº—å®¶å„é¢å‘è©•åƒ¹ï¼š")
    for cat, scores in category_sentiments.items():
        if scores:
            avg_score = sum(scores) / len(scores)
            if avg_score > 3:
                overall = "æ­£é¢"
            elif avg_score == 3:
                overall = "ä¸­ç«‹"
            else:
                overall = "è² é¢"
            print(f"  {cat}ï¼šå¹³å‡åˆ†æ•¸ {avg_score:.2f}ï¼Œç¸½é«”ï¼š{overall}")
            # å„²å­˜åˆ° RestaurantIndicatorDetail
            RestaurantIndicatorDetail.objects.create(
                place_id=place_id,
                indicator_type=cat,
                score=avg_score,
                source="post",
                source_id=post.id,
                created_at=timezone.now(),
                updated_at=timezone.now()
            )

