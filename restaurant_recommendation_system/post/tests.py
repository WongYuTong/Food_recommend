import emoji

from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger
from transformers import pipeline
from tqdm import tqdm
import re
from keybert import KeyBERT

if __name__ == "__main__":
    def clean_text(text):
        # ç§»é™¤ emoji
        text = emoji.replace_emoji(text, replace='')
        # å¯åœ¨æ­¤åŠ å…¥æ›´å¤šé›œè¨Šæ¸…ç†è¦å‰‡ï¼ˆå¦‚å¤šé¤˜ç©ºç™½ã€ç‰¹æ®Šç¬¦è™Ÿç­‰ï¼‰
        text = re.sub(r'[\s]+', ' ', text)
        return text.strip()
    # åˆå§‹åŒ–æ¨¡å‹
    ws_driver = CkipWordSegmenter(model="bert-base")
    pos_driver = CkipPosTagger(model="bert-base")
    zero_shot = pipeline("zero-shot-classification", model="joeddav/xlm-roberta-large-xnli")
    sentiment = pipeline("zero-shot-classification", model="MoritzLaurer/mDeBERTa-v3-base-mnli-xnli")
    kw_model = KeyBERT(model='paraphrase-multilingual-MiniLM-L12-v2')

    print("\n====== åº—å®¶è©•è«–åˆ†æ ======")
    fake_posts = [
        "é€™å®¶ç«é‹çš„æ¹¯é ­å¾ˆæ£’ï¼Œæœå‹™ç”Ÿæ…‹åº¦è¦ªåˆ‡ï¼Œåƒ¹æ ¼ä¹Ÿå¾ˆåˆç†ï¼Œä¸‹æ¬¡é‚„æœƒå†ä¾†ï¼",
        "å£½å¸ä¸æ–°é®®ï¼Œç’°å¢ƒæœ‰é»é«’äº‚ï¼Œæœå‹™ä¹Ÿä¸å¤ªå¥½ã€‚",
        "ç‰›æ’å¾ˆå¥½åƒï¼ŒCPå€¼é«˜ï¼Œæ¨è–¦çµ¦å¤§å®¶ï¼",
        "å†°æ·‡æ·‹å£å‘³æ™®é€šï¼Œæœå‹™é€Ÿåº¦å¾ˆæ…¢ã€‚",
        "æ‹‰éºµæ¹¯é ­å¤ªé¹¹ï¼Œåƒ¹æ ¼åè²´ï¼Œä½†ç’°å¢ƒå¾ˆèˆ’é©ã€‚",
        "æ‹‰éºµæ¹¯é ­å¾ˆé¹¹ä½†æ˜¯æˆ‘å¾ˆå–œæ­¡XD",
        "æ‹‰éºµæ¹¯é ­å¾ˆé¹¹ï¼Œä½†æ˜¯æˆ‘å¾ˆå–œæ­¡XD",
        "æ¨“ä¸Šé¢¨æ™¯å¾ˆå¥½çœ‹ï¼Œé»äº†æ˜†å¸ƒç«é‹å’Œå‘³å™Œç«é‹ï¼Œé£²æ–™é‚„æœ‰å¯ä»¥åŠ åˆ°ç«é‹çš„èœè·Ÿé†¬æ–™å¾ˆå¤šå…ƒï¼Œéœœæ·‡æ·‹å¯ä»¥è‡ªå·±åšï¼Œé‚„æœ‰å¾ˆå¤šå°æ–™å¯ä»¥åŠ ï¼Œè¶…è®šğŸ‘ğŸ‘ï¼Œä¸‹æ¬¡é‚„è¦ä¾†åƒğŸ˜Š",
        "é¤é»ç¾å‘³ä»½é‡åè¶³ï¼Œä¸»å»šæ‰‹è—ä¸€æµï¼Œé‚„æœ‰æ“ºç›¤è£é£¾è³ªæ„Ÿå‡ç´šï¼Œå¸Œæœ›å¢åŠ ä¸€äº›é’èœé¡æˆ–èƒ½å–®é»å°±æ›´å®Œç¾äº†ï¼",
        "è‚‰å“å¥½åƒï¼Œå°èœå¯ä»¥ä¸€ç›´çºŒï¼Œcpå€¼éå¸¸é«˜",
        "ç²¾ç·»ç‡’è‚‰ï¼å¾ˆä¸éŒ¯ğŸ‘",
        "åƒéŸ“åœ‹äººçš„å§Šå§Šçƒ¤è‚‰è¶…å¥½åƒï¼Œæœå‹™ä¹Ÿå¾ˆåˆ°ä½ï¼Œåƒ¹éŒ¢é…å¾—ä¸Šå“è³ªè·Ÿæœå‹™",
        "å¾ˆå¥½åƒå‘¦ï½ æœå‹™äººå“¡æ…‹åº¦éƒ½å¾ˆå¥½ï½ï½ å¾ˆå¤šå°ç´°ç¯€æœå‹™äººå“¡éƒ½æœƒæ³¨æ„ï¼"
    ]
    candidate_labels = ["é«”é©—", "é£Ÿç‰©", "æœå‹™", "åƒ¹æ ¼", "ç’°å¢ƒ", "å…¶ä»–"]
    sentiment_labels = ["æ­£é¢", "ä¸­ç«‹", "è² é¢"]
    overall_keywords = ["å†ä¾†", "æ¨è–¦", "ä¸æœƒå†ä¾†", "ä¸‹æ¬¡", "å¤§å®¶", "å€¼å¾—", "ä¸æ¨", "ä¸æ¨è–¦"]
    for idx, content in enumerate(tqdm(fake_posts, desc="åˆ†æåº—å®¶è©•è«–")):
        print(f"\n=== è©•è«–{idx+1} ===")
        print("åŸæ–‡ï¼š", content)
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ!ï¼Ÿï¼Œ,ï½~]+|\\s{2,}', content)
        sentences = [s for s in sentences if s.strip()]
        ws_list = ws_driver(sentences)
        pos_list = pos_driver(ws_list)
        stopwords = set(["çš„", "äº†", "å’Œ", "å¯ä»¥", "é‚„æœ‰", "å¾ˆå¤š", "è‡ªå·±", "åˆ°", "è·Ÿ", "æœ‰", "æ˜¯", "åœ¨", "è¦", "å¾ˆ", "ä¸", "å†", "æœƒ", "ä¾†", "åŠ ", "åš"])
        valid_pos = set(["Na", "Nb", "Nc", "A", "V"])
        last_keywords = None
        sentence_to_keywords = []
        keyword_to_category = {}
        keyword_to_sentences = {}
        for sent, ws, pos in zip(sentences, ws_list, pos_list):
            is_summary = any(kw in sent for kw in overall_keywords)
            # CKIP æ–·è©+è©æ€§éæ¿¾+å»é™¤åœç”¨è©+é•·åº¦>1
            ckip_words = [w for w, p in zip(ws, pos) if p in valid_pos and w not in stopwords and len(w) > 1]
            # KeyBERT é—œéµè©ï¼ˆé™åˆ¶é•·åº¦6ä»¥å…§ï¼‰
            keybert_keywords = [kw for kw, score in kw_model.extract_keywords(sent, top_n=2) if len(kw) <= 6]
            # åˆä½µä¸¦å»é‡ï¼ˆä¿ç•™æœ€çŸ­çš„é—œéµè©ï¼‰
            all_keywords = ckip_words + keybert_keywords
            keywords = []
            for k in all_keywords:
                if not any((k != other and k in other) for other in all_keywords):
                    keywords.append(k)
            keywords = list(dict.fromkeys(keywords))  # å»é‡ä¸”ä¿ç•™é †åº
            print(f"å¥å­ï¼šã€Œ{sent}ã€â†’ é—œéµè©ï¼š{keywords}")
            if keywords:
                last_keywords = keywords
                for keyword in keywords:
                    if keyword not in keyword_to_category:
                        # summary/overall é—œéµè©ç›´æ¥åˆ†é¡ç‚ºé«”é©—
                        if any(kw in keyword for kw in overall_keywords):
                            best_label = "é«”é©—"
                            score = 1.0
                        # å¸Œæœ›/å»ºè­°/æœŸæœ›/å¦‚æœèƒ½/å¸Œæœ›èƒ½ ç›´æ¥åˆ†é¡ç‚ºå…¶ä»–
                        elif any(x in keyword for x in ["å¸Œæœ›", "å»ºè­°", "æœŸæœ›", "å¦‚æœèƒ½", "å¸Œæœ›èƒ½"]):
                            best_label = "å…¶ä»–"
                            score = 1.0
                        elif "åƒ¹æ ¼" in keyword or "è²´" in keyword or "ä¾¿å®œ" in keyword or "CP" in keyword:
                            best_label = "åƒ¹æ ¼"
                            score = 1.0
                        elif any(food in keyword for food in ["å°æ–™","æ¹¯é ­", "å£å‘³","é£²æ–™"]):
                            best_label = "é£Ÿç‰©"
                            score = 1.0
                        elif any(env in keyword for env in ["æ¨“ä¸Š", "é¢¨æ™¯", "è£æ½¢", "æ°£æ°›", "ç’°å¢ƒ", "åœ°é»", "ä½ç½®", "ç©ºé–“"]):
                            best_label = "ç’°å¢ƒ"
                            score = 1.0
                        elif any(srv in keyword for srv in ["ç´°ç¯€", "äººå“¡", "æ…‹åº¦"]):
                            best_label = "æœå‹™"
                            score = 1.0
                        else:
                            result = zero_shot(keyword, candidate_labels=candidate_labels)
                            best_label = result['labels'][0]
                            score = result['scores'][0]
                        # å¦‚æœåˆ†é¡ç‚ºå…¶ä»–ï¼Œå‰‡é‡å°æ•´å¥å†åšä¸€æ¬¡ zero-shot åˆ†é¡
                        if best_label == "å…¶ä»–":
                            sent_result = zero_shot(sent, candidate_labels=candidate_labels)
                            sent_label = sent_result['labels'][0]
                            sent_score = sent_result['scores'][0]
                            if sent_label != "å…¶ä»–" and sent_score > 0.5:
                                best_label = sent_label
                                score = sent_score
                        if best_label != "å…¶ä»–" and score <= 0.5:
                            continue
                        keyword_to_category[keyword] = best_label
                        keyword_to_sentences.setdefault(keyword, []).append(sent)
            else:
                if last_keywords:
                    for keyword in last_keywords:
                        keyword_to_sentences.setdefault(keyword, []).append(sent)
            sentence_to_keywords.append(last_keywords)
        category_sentiments = {cat: [] for cat in candidate_labels}
        # rule-based emoji/æ¥µç«¯è©å½™æƒ…æ„Ÿåˆ¤æ–·
        positive_emojis = ["ğŸ˜Š", "ğŸ‘", "XD", "ğŸ˜‚", "ğŸ˜", ":D", ":)", "^_^", "^O^", "ğŸ˜ƒ", "ğŸ˜„", "ğŸ˜†", "ğŸ˜", "ğŸ¥°", "ğŸ˜‹", "ğŸ˜"]
        negative_emojis = ["ğŸ˜¡", "ğŸ‘", "QQ", "å“­", ":(", ">:(", "T_T", "QAQ", "ğŸ˜¢", "ğŸ˜", "ğŸ˜ ", "ğŸ˜£", "ğŸ˜–", "ğŸ˜”"]
        # åƒ…æ¥µç«¯è©å½™ç›´æ¥çµ¦æ¥µç«¯åˆ†æ•¸
        positive_extreme_words = ["è¶…è®š", "è¶…æ£’", "è¶…å¥½åƒ", "è¶…æ»¿æ„", "è¶…æ¨è–¦", "è¶…å–œæ­¡", "è¶…å€¼"]
        negative_extreme_words = ["è¶…çˆ›", "è¶…é›£åƒ", "è¶…å¤±æœ›", "è¶…ç³Ÿç³•", "è¶…å·®", "è¶…è¨å­"]
        # ä¸€èˆ¬æƒ…æ„Ÿè©äº¤çµ¦æ¨¡å‹åˆ¤æ–·
        neutral_patterns = ["é»äº†"]
        sentiment_words = ["å¥½åƒ", "é›£åƒ", "æ¨è–¦", "å¤±æœ›", "æ»¿æ„", "è¨å­", "æ£’", "å–œæ­¡", "æ¨", "ä¸æ¨", "ä¸æ¨è–¦", "ä¸å€¼å¾—", "å€¼å¾—", "è®š"]
        summary_positive = ["ä¸‹æ¬¡é‚„è¦ä¾†åƒ", "ä¸‹æ¬¡é‚„æœƒå†ä¾†", "é‚„è¦ä¾†", "é‚„æœƒä¾†", "å€¼å¾—", "æ¨è–¦çµ¦å¤§å®¶"]
        weaken_words = ["æœ‰é»", "ç¨å¾®", "æœ‰äº›"]
        def has_sentiment_word(sent, sentiment_words):
            return any(w in sent for w in sentiment_words)
        for keyword, cat in keyword_to_category.items():
            # æ–°å¢ï¼šè¨˜éŒ„æ¯åˆ†é¡å·²åŠ éåˆ†æ•¸çš„å¥å­
            if 'cat_sent_added' not in locals():
                cat_sent_added = {c: set() for c in candidate_labels}
            first_print = True
            for sent in keyword_to_sentences.get(keyword, []):
                # è·³éï¼šåŒä¸€å¥è©±å·²åŠ éè©²åˆ†é¡åˆ†æ•¸
                if sent in cat_sent_added[cat]:
                    continue
                if first_print:
                    print(f"\n  é—œéµè©ï¼š{keyword}ï¼ˆåˆ†é¡ï¼š{cat}ï¼‰")
                    first_print = False
                
                # emoji/æ¥µç«¯è©å½™åŠ åˆ†æˆ–æ‰£åˆ†
                pos_bonus = 0.2 if (any(e in sent for e in positive_emojis) or any(w in sent for w in positive_extreme_words)) else 0.0
                neg_bonus = 0.2 if (any(e in sent for e in negative_emojis) or any(w in sent for w in negative_extreme_words)) else 0.0
                # æ¸…é™¤ emoji èˆ‡é›œè¨Š
                sent_for_model = clean_text(sent)
                # æ˜é¡¯æ­£é¢ summary é—œéµè©ç›´æ¥çµ¦æ­£é¢åˆ†æ•¸ï¼ˆéæ¥µç«¯ï¼‰
                if any(sp in sent_for_model for sp in summary_positive):
                    sent_label = "æ­£é¢"
                    sent_score = 0.5
                # ç´”æè¿°å¥ä¸”ç„¡æƒ…æ„Ÿè©ï¼Œåˆ¤æ–·ç‚ºä¸­ç«‹
                elif any(p in sent_for_model for p in neutral_patterns) and not has_sentiment_word(sent_for_model, sentiment_words):
                    sent_label = "ä¸­ç«‹"
                    sent_score = 0.0
                else:
                    sent_result = sentiment(sent_for_model, candidate_labels=sentiment_labels)
                    sent_label = sent_result['labels'][0]
                    sent_score = sent_result['scores'][0]
                # åŠ åˆ†æˆ–æ‰£åˆ†
                if sent_label == "æ­£é¢":
                    score_val = sent_score + pos_bonus - neg_bonus
                elif sent_label == "è² é¢":
                    score_val = -sent_score - neg_bonus + pos_bonus
                else:
                    score_val = 0 + pos_bonus - neg_bonus
                # èªæ°£è©å¼±åŒ–èª¿æ•´
                if any(w in sent for w in weaken_words):
                    if sent_label == "æ­£é¢":
                        score_val -= 0.35  # æ­£é¢èªæ°£å¼±åŒ–
                    elif sent_label == "è² é¢":
                        score_val += 0.35  # è² é¢èªæ°£å¼±åŒ–
                # åˆ†æ•¸é™åˆ¶åœ¨[-1, 1]
                score_val = max(min(score_val, 1.0), -1.0)

                # è½‰æ›ç‚º1~5åˆ†åˆ¶ï¼ˆç´°åˆ†å€é–“ï¼‰
                if sent_label == "è² é¢":
                    # -1 ~ -0.5 å°æ‡‰ 1~2åˆ†
                    if score_val <= -0.5:
                        mapped_score = 1 + (score_val + 1) * (1/0.5)  # -1~ -0.5 â†’ 1~2
                        mapped_score = min(max(mapped_score, 1), 2)
                    else:
                        # -0.5 ~ 0 å°æ‡‰ 2~3åˆ†
                        mapped_score = 2 + (score_val + 0.5) * (1/0.5)  # -0.5~0 â†’ 2~3
                        mapped_score = min(max(mapped_score, 2), 3)
                elif sent_label == "ä¸­ç«‹":
                    mapped_score = 3
                else:  # æ­£é¢
                    # 0 ~ 0.5 å°æ‡‰ 3~4åˆ†
                    if score_val <= 0.5:
                        mapped_score = 3 + score_val * (1/0.5)  # 0~0.5 â†’ 3~4
                        mapped_score = min(max(mapped_score, 3), 4)
                    else:
                        # 0.5 ~ 1 å°æ‡‰ 4~5åˆ†
                        mapped_score = 4 + (score_val - 0.5) * (1/0.5)  # 0.5~1 â†’ 4~5
                        mapped_score = min(max(mapped_score, 4), 5)

                print(f"    å¥å­ï¼šã€Œ{sent}ã€â†’ æƒ…æ„Ÿï¼š{sent_label}ï¼ˆåŸåˆ†æ•¸ï¼š{score_val:.2f}ï¼Œäº”åˆ†åˆ¶ï¼š{mapped_score:.2f}ï¼‰")
                category_sentiments[cat].append(mapped_score)
                cat_sent_added[cat].add(sent)
        print("\nåº—å®¶å„é¢å‘è©•åƒ¹ï¼š")
        for cat, scores in category_sentiments.items():
            if scores:
                avg_score = sum(scores) / len(scores)
                if avg_score > 3:
                    overall = "æ­£é¢"
                elif avg_score == 3:
                    overall = "ä¸­ç«‹"
                else:
                    overall = "è² é¢"
                print(f"  {cat}ï¼šå¹³å‡åˆ†æ•¸ {avg_score:.2f}ï¼Œç¸½é«”ï¼š{overall}")